# Awesome - Most Cited and Impactful Papers on AI Video generation
A curated list of papers on video generation or editing using Generative Models such as Diffusion Models, Generative Adversarial Networks (GANs), etc.

Though the name of the repo is `text-to-video`, all sorts of modalities to video such as `text+image` to video are also included and contributions are welcome.

The papers are grouped based on the main model architecture of the generative model. 

## Why this Awesome list 
This awesome list is created to help researchers and practisioners get up to speed with generative models for video generation and editing. Anyone getting started, say a new PhD student, should be able to make the most out of this repo.

## Contributing
If you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and send across a pull request.

## Contents
* [Latent Diffusion Models](#Latent--Diffusion--Models)
* [Generative Adversarial Networks](#Generative--Adversarial--Networks--(GANs))
* [Autoregressive Models](#Autoregressive-Models)
* * *

### Latent Diffusion Models
- Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets - [[pdf]](https://static1.squarespace.com/static/6213c340453c3f502425776e/t/655ce779b9d47d342a93c890/1700587395994/stable_video_diffusion.pdf)
- Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning - [[pdf]](https://arxiv.org/pdf/2311.10709.pdf)
- 

### Autoregressive Models

### Generative Adversarial Networks (GANs)


